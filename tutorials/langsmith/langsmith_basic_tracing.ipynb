{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GoAgj6L0J_HY"
   },
   "source": [
    "### LangSmith Walkthrough\n",
    "\n",
    "#### Resources\n",
    "- [langsmith cookbook](https://github.com/langchain-ai/langsmith-cookbook/blob/main/tracing-examples/traceable/tracing_without_langchain.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-n8HafTN94ew",
    "outputId": "699de298-0580-43b1-cc39-bde877401062"
   },
   "outputs": [],
   "source": [
    "!pip install langsmith langchain anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "LjvIHQPqDK8Y",
    "outputId": "041ce72b-f657-42bd-9372-34211873a0fb"
   },
   "outputs": [],
   "source": [
    "import langsmith, os, sys\n",
    "import anthropic as anthropic_base\n",
    "from langsmith import traceable\n",
    "from pathlib import Path \n",
    "\n",
    "_root = \"/home/zjc1002/Mounts/code/admin/\"\n",
    "\n",
    "\n",
    "sys.path.append(_root)\n",
    "from api_keys import _api_keys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQ3UCb0j_6m4"
   },
   "source": [
    "### Langsmith API Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oImoFpdF_nV5"
   },
   "outputs": [],
   "source": [
    "!export LANGSMITH_TRACING_v2=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbjr820u_4Ry"
   },
   "outputs": [],
   "source": [
    "LANGSMITH_TRACING=True\n",
    "LANGSMITH_ENDPOINT='https://api.smith.langchain.com'\n",
    "LANGSMITH_PROJECT=\"LangSmith Basics\"\n",
    "\n",
    "LANGSMITH_API_KEY= _api_keys[\"LANGSMITH_API_KEY\"]\n",
    "ANTHROPIC_API_KEY=_api_keys['ANTHROPIC_API_KEY']\n",
    "ANTHROPIC_MODEL='claude-3-haiku-20240307'\n",
    "\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = LANGSMITH_ENDPOINT\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGSMITH_API_KEY\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = LANGSMITH_PROJECT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7aaZAsqMC5RJ"
   },
   "source": [
    "### Create LLM INSTANCE\n",
    "##### Note: I am using anthropic, but u should be able to use any model open source or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zRl115O4DCIW",
    "outputId": "34cc9169-8b8f-4deb-df96-df74490501b4"
   },
   "outputs": [],
   "source": [
    "client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oAqW-bnNHN8B"
   },
   "source": [
    "#### Trace a basic function\n",
    "\n",
    "- **@traceable** decorator is ment to manage the logging of events from the client using a RunTree, which tracks your application. Each RunTree is required to have the below paramters\n",
    "   - **name:str**: used to id the components purpose\n",
    "   - **run_type:str**: 'llm','chain', or 'tool'. describes the type of interaction / activity being logged\n",
    "   - **inputs:dict**: the inputs to the component\n",
    "   - **outputs:Optional[dict]**: the (optinal) returned values from the component\n",
    "   - **error: Optional[str]**: any error messages that may have arisin during the call\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oNROA_CrEWF3",
    "outputId": "f3a7bcf2-8eb8-4f06-8b95-cc1d237b729d"
   },
   "outputs": [],
   "source": [
    "@traceable # Auto-trace this function\n",
    "def pipeline(client, user_input: str, model = None):\n",
    "\n",
    "    assert model is not None, \"Model must be specified, only ANTHROPIC models currently supported\"\n",
    "    result = client.messages.create(\n",
    "        model= model\n",
    "        , max_tokens = 1000\n",
    "        , messages=[{\"role\": \"user\", \"content\": user_input}],\n",
    "\n",
    "    )\n",
    "    return result.content[0]\n",
    "\n",
    "pipeline(client, \"Hello, world!\", model = ANTHROPIC_MODEL)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "langy2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
