{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GoAgj6L0J_HY"
   },
   "source": [
    "### LangSmith Walkthrough\n",
    "\n",
    "#### Resources\n",
    "- [langsmith cookbook](https://github.com/langchain-ai/langsmith-cookbook/blob/main/tracing-examples/traceable/tracing_without_langchain.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-n8HafTN94ew",
    "outputId": "699de298-0580-43b1-cc39-bde877401062"
   },
   "outputs": [],
   "source": [
    "!pip install langsmith langchain anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "LjvIHQPqDK8Y",
    "outputId": "041ce72b-f657-42bd-9372-34211873a0fb"
   },
   "outputs": [],
   "source": [
    "import langsmith, os, sys\n",
    "import anthropic as anthropic_base\n",
    "from langsmith import traceable\n",
    "from pathlib import Path \n",
    "\n",
    "_root = \"/home/zjc1002/Mounts/code/admin/\"\n",
    "\n",
    "\n",
    "sys.path.append(_root)\n",
    "from api_keys import _api_keys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQ3UCb0j_6m4"
   },
   "source": [
    "### Langsmith API Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oImoFpdF_nV5"
   },
   "outputs": [],
   "source": [
    "!export LANGSMITH_TRACING_v2=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbjr820u_4Ry"
   },
   "outputs": [],
   "source": [
    "LANGSMITH_TRACING=True\n",
    "LANGSMITH_ENDPOINT='https://api.smith.langchain.com'\n",
    "LANGSMITH_PROJECT=\"LangSmith Basics\"\n",
    "\n",
    "LANGSMITH_API_KEY= _api_keys[\"LANGSMITH_API_KEY\"]\n",
    "ANTHROPIC_API_KEY=_api_keys['ANTHROPIC_API_KEY']\n",
    "ANTHROPIC_MODEL='claude-3-haiku-20240307'\n",
    "\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = LANGSMITH_ENDPOINT\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGSMITH_API_KEY\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = LANGSMITH_PROJECT\n",
    "\n",
    "!export LANGSMITH_TRACING=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Sample Parameters to test LangSmith With "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_p = \"You are a helpful assistant. Please respond to the user's request only based on the given context.\"\n",
    "question = 'where are the best grits in Charlotte'\n",
    "context = \"Charlotte has alot of grits. But Hands down the best grits are from The Flying Biscuit, with a close second being Waffle House. \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7aaZAsqMC5RJ"
   },
   "source": [
    "### Create LLM INSTANCE\n",
    "##### Note: I am using anthropic, but u should be able to use any model open source or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zRl115O4DCIW",
    "outputId": "34cc9169-8b8f-4deb-df96-df74490501b4"
   },
   "outputs": [],
   "source": [
    "client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "owner = client.__class__.__module__.split('.')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oAqW-bnNHN8B"
   },
   "source": [
    "#### Trace a basic function\n",
    "\n",
    "- **@traceable** decorator is ment to manage the logging of events from the client using a RunTree, which tracks your application. Each RunTree is required to have the below paramters\n",
    "   - **name:str**: used to id the components purpose\n",
    "   - **run_type:str**: 'llm','chain', or 'tool'. describes the type of interaction / activity being logged\n",
    "   - **inputs:dict**: the inputs to the component\n",
    "   - **outputs:Optional[dict]**: the (optinal) returned values from the component\n",
    "   - **error: Optional[str]**: any error messages that may have arisin during the call\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oNROA_CrEWF3",
    "outputId": "f3a7bcf2-8eb8-4f06-8b95-cc1d237b729d"
   },
   "outputs": [],
   "source": [
    "# Use the @traceable decorator with the 'project_name' parameter to log traces to LangSmith\n",
    "# Ensure that the LANGCHAIN_TRACING_V2 environment variables are set for @traceable to work\n",
    "\n",
    "@traceable(run_type=\"llm\"\n",
    ", name=LANGSMITH_PROJECT\n",
    ", metadata = {'ls_provider':owner ,'ls_model_name':ANTHROPIC_MODEL}\n",
    ")\n",
    "\n",
    "def argument_generator(client, user_input: str, model = None , additional_system_prompt_details:str = \"\"):\n",
    "\n",
    "    assert model is not None, \"Model must be specified, only ANTHROPIC models currently supported\"\n",
    "\n",
    "    result = client.messages.create(\n",
    "        model= model\n",
    "        , max_tokens = 1000\n",
    "        , temperature = .1\n",
    "        , system = f\"you are a general use chatbot tying to help people awnser questions. {additional_system_prompt_details}. The current time is {datetime.now()}\"\n",
    "        , messages=[\n",
    "            {\"role\": \"user\", \"content\": user_input}]\n",
    "    )\n",
    "\n",
    "    return result.content[0]\n",
    "\n",
    "\n",
    "@traceable(name=LANGSMITH_PROJECT)\n",
    "def argument_chain(client,  model, user_input: str, additional_system_prompt_details:str = \"\"):\n",
    "\n",
    "    argument = argument_generator(client\n",
    "                                  , user_input\n",
    "                                  , model=model\n",
    "                                  , additional_system_prompt_details=additional_system_prompt_details\n",
    "                                  )\n",
    "\n",
    "    return argument\n",
    "\n",
    "argument_chain(client, ANTHROPIC_MODEL, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracing LLM Calls Explicitly with RunTree API\n",
    "\n",
    "###### *enables you to manually create runs and children runs to assemble your trace*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.run_trees import RunTree\n",
    "from uuid import uuid4\n",
    "\n",
    "#specify run_id for tracking (optional)\n",
    "run_id = uuid4()\n",
    "\n",
    "#create a top-level run\n",
    "pipeline = RunTree(name=LANGSMITH_PROJECT\n",
    "                   , run_type=\"chain\"\n",
    "                   , inputs = {\"question\":question}\n",
    "                   , metadata={'ls_provider':owner, 'ls_model_name':ANTHROPIC_MODEL}\n",
    "                   , id= run_id\n",
    "                   )\n",
    "\n",
    "#post the tree to the LangSmith platform for storage and later analysis\n",
    "pipeline.post()\n",
    "\n",
    "#ask a question given specific context\n",
    "messages = [\n",
    "  { \"role\": \"user\", \"content\": f\"Question: {question}\\nContext: {context}\"}\n",
    "]\n",
    "\n",
    "\n",
    "#create a child run (passing query and context to llm)\n",
    "child_llm_run = pipeline.create_child(\n",
    "    name = 'Anthropic Call'\n",
    "    , run_type = 'llm'\n",
    "    , inputs= messages\n",
    ")\n",
    "\n",
    "child_llm_run.post()\n",
    "\n",
    "#generate simple completion\n",
    "result = client.messages.create(\n",
    "      model= ANTHROPIC_MODEL\n",
    "      , max_tokens = 1000\n",
    "      , temperature = .1\n",
    "      , system = system_p\n",
    "      , messages=messages\n",
    "    )\n",
    "\n",
    "\n",
    "#End the child trace and log it\n",
    "child_llm_run.end(outputs=result)\n",
    "child_llm_run.patch()\n",
    "\n",
    "\n",
    "#End the parent trace and log it\n",
    "pipeline.end(outputs={'anwser':result.content[0]})\n",
    "pipeline.patch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE LANGSMITH CLIENT TO GET URL OF CURRNET RUNID BEING TRACKED\n",
    "from langsmith import Client\n",
    "_client = Client()\n",
    "run = _client.read_run(run_id)\n",
    "print(run.url)\n",
    "\n",
    "#DELETE TRACES TIED TO PROJECT\n",
    "Client().delete_project(project_name=LANGSMITH_PROJECT)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "langy2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
